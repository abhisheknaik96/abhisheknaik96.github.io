I"<p>Back when I first read <a href="http://www.incompleteideas.net/book/the-book.html">the RL textbook</a>, the Bellman Equation for the <em>discounted</em> value function was introduced as:</p>

<p><img src="/images/BellmanEquation_book.png" alt="Eq 3.14 from Pg 46" /></p>

<p>Now, I felt there was a big jump from the third equation to the fourth, so recently I came back to it. Turns out, the derivation from that third equation the the fourth was quite significant! So let’s break it down:</p>

\[\begin{aligned}
v_{\pi}(s) &amp;= \mathbb{E}[G_t | S_t = s]\\
&amp;= \mathbb{E}[R_{t+1} + \gamma G_{t+1}| S_t = s]\\
&amp;= \mathbb{E}[R_{t+1}|S_t=s] + \gamma \mathbb{E}[G_{t+1}| S_t = s] \qquad (1)
\end{aligned}\]

<p>Before we expand these two terms, let us revisit some basic probability.</p>

\[\begin{aligned}
\mathbb{E}[A] = \mathbb{E}\big[\mathbb{E}[A|B]\big]
\end{aligned}\]

<p>Why is this true? Let’s expand the RHS.</p>

\[\begin{aligned} \mathbb{E}\big[\mathbb{E}[A|B]\big] &amp;= \sum_{b\in\mathcal{B}} p(B=b)\;\mathbb{E}[A|B=b] \\
&amp;= \sum_{b\in\mathcal{B}} p(B=b) \sum_{a\in\mathcal{A}}a\;p(A=a|B=b)\\
&amp;= \sum_{b\in\mathcal{B}}  \sum_{a\in\mathcal{A}}a\;p(B=b)\;p(A=a|B=b)\\
&amp;= \sum_{b\in\mathcal{B}} \sum_{a\in\mathcal{A}}a\;p(A=a,B=b)\\
&amp;= \sum_{a\in\mathcal{A}}a\;\sum_{b\in\mathcal{B}}p(A=a,B=b)\\
&amp;= \sum_{a\in\mathcal{A}}a\;p(A=a)\\
&amp;=\mathbb{E}[A]
\end{aligned}\]

<p>What we did here is condition over another random variable and marginalize over it. Keeping this in mind, let us go back to the first term on the RHS in equation 1.</p>

\[\begin{aligned}
\mathbb{E}[R_{t+1}|S_t=s] &amp;= \mathbb{E}\big[\mathbb{E}[R_{t+1}|S_t=s,A_t]\big]\\
&amp;= \sum_{a}p(A_t=a|S_t=s)\;\mathbb{E}[R_{t+1}|S_t=s,A_t=a]\\
&amp;= \sum_{a}\pi(a|s)\;\mathbb{E}[R_{t+1}|S_t=s,A_t=a]\\
&amp;= \sum_{a}\pi(a|s)\;\mathbb{E}\big[\mathbb{E}[R_{t+1}|S_t=s,A_t=a,S_{t+1}]\big]\\
&amp;= \sum_{a}\pi(a|s)\;\sum_{s'}p(s'|s,a)\mathbb{E}[R_{t+1}|S_t=s,A_t=a,S_{t+1}=s']\\
&amp;= \sum_{a}\pi(a|s)\;\sum_{s'}p(s'|s,a)\;r(s,a,s') \qquad (2)
\end{aligned}\]

<p>Here, \(r(s,a,s')\) is the <em>expected</em> reward when action \(a\) is state \(s\) leads to state \(s'\).</p>

<p>Next, the second term (without \(\gamma\)) in the RHS of equation 1 can be similarly expanded as:</p>

\[\begin{aligned}
\mathbb{E}[G_{t+1}| S_t = s] &amp;= \mathbb{E}\big[\mathbb{E}[G_{t+1}| S_t = s, S_{t+1}]\big] \\
&amp;= \sum_{s'} \mathbb{E}[G_{t+1}| S_t = s, S_{t+1}=s']\; p(s'|s) \\
&amp;= \sum_{s'}  \mathbb{E}[G_{t+1}| S_t = s, S_{t+1}=s'] \sum_a p(a|s)\;p(s'|s,a)\\
&amp;= \sum_a \pi(a|s) \sum_{s'} p(s'|s,a) \mathbb{E}[G_{t+1}| S_t = s, S_{t+1}=s']\\
&amp;= \sum_a \pi(a|s) \sum_{s'} p(s'|s,a) \mathbb{E}[G_{t+1}| S_{t+1}=s'] \qquad (3)
\end{aligned}\]

<p>Substituting equations 2 and 3 back in 1, we get:</p>

\[\begin{aligned}
v_{\pi}(s) &amp;= \sum_{a}\pi(a|s)\;\sum_{s'}p(s'|s,a)\;r(s,a,s') \\
&amp;\quad + \gamma \sum_a \pi(a|s) \sum_{s'} p(s'|s,a)\;\mathbb{E}[G_{t+1}| S_t = s, S_{t+1}=s']\\
&amp;= \sum_a \pi(a|s) \sum_{s'} p(s'|s,a) \big[r(s,a,s') + \gamma \mathbb{E}[G_{t+1}| S_t = s, S_{t+1}=s']\big]\\
&amp;= \sum_a \pi(a|s) \sum_{s'} p(s'|s,a) \big[r(s,a,s') + \gamma  \mathbb{E}[G_{t+1}|S_{t+1}=s']\big]\\
v_{\pi}(s) &amp;= \sum_a \pi(a|s) \sum_{s'} p(s'|s,a) \big[r(s,a,s') + \gamma v_\pi(s')\big] \qquad (4)
\end{aligned}\]

<p align="center">
Tadaa!
</p>

<p>Wait, you say, the Bellman equation in the book looks different from this…</p>

<p><img src="/images/BellmanEquation_book_small.png" alt="Eq 3.14 from Pg 46" /></p>

<!-- Hmm... Well, it turns out that that requires another assumption: the reward obtained per timestep depends only on the current state $$s$$ and the action $$a$$ taken in it, and not the next state $$s'$$.
Another way to look at it is that the reward $$r$$ and next state $$s'$$ are jointly conditional on the current state $$s$$ and action $$a$$, resulting in the joint distribution $$p(s',r|s,a)$$. Given this, the derivation becomes more straightforward (_and is left to the reader as an exercise :P I've always wanted to say that!_)

If that is the case, then equation 2 can be re-written as:

$$ \begin{aligned}
v_{\pi}(s) &= \sum_{a}\pi(a|s)\;\sum_{s'}p(s'|s,a)\;r(s,a,s')\\
&= \sum_{a}\pi(a|s)\;\sum_{s'}p(s'|s,a)\;\mathbb{E}[R_{t+1}|S_t=s,A_t=a,S_{t+1}=s']\\
&= \sum_{a}\pi(a|s)\;\sum_{s'}p(s'|s,a)\;\mathbb{E}[R_{t+1}|S_t=s,A_t=a]\\
&= \sum_{a}\pi(a|s)\;\sum_{s'}p(s'|s,a)\;\sum_{s'}p(r|s,a)\;r\\
&= \sum_{a}\pi(a|s)\;\sum_{s',r}p(s',r|s,a)\;r \qquad (5)
\end{aligned} $$ -->

<p>Hmm, let us look at the first term again:</p>

\[\begin{aligned}
\text{First term} &amp;= \sum_{a}\pi(a|s)\;\sum_{s'}p(s'|s,a)\;r(s,a,s')\\
&amp;= \sum_{a}\pi(a|s)\;\sum_{s'}p(s'|s,a)\;\mathbb{E}[R_{t+1}|S_t=s,A_t=a,S_{t+1}=s']\\
&amp;= \sum_{a}\pi(a|s)\;\sum_{s'}p(s'|s,a)\sum_{r}p(r|s,a,s')\,r\\
&amp;= \sum_{a}\pi(a|s)\;\sum_{s'}\sum_{r}p(s'|s,a)p(r|s,a,s')\,r\\
&amp;= \sum_{a}\pi(a|s)\;\sum_{s',r}p(s',r|s,a)\,r \qquad (5)
\end{aligned}\]

<p>Starting to look more familiar, eh?</p>

<p>What happened in the last step there, you ask. Well, we applied the chain rule of conditional probability:</p>

\[\begin{aligned}
P(A|B,C,D)P(B|C,D) &amp;= \dfrac{P(A,B,C,D)}{P(B,C,D)} \dfrac{P(B,C,D)}{P(C,D)} \\
&amp;= \dfrac{P(A,B,C,D)}{P(C,D)} \\
&amp;= P(A,B|C,D)
\end{aligned}\]

<p>We can also re-write the second term. There is no reward term here, and so:</p>

\[\begin{aligned}
\mathbb{E}[G_{t+1}| S_t = s]
&amp;= \sum_a \pi(a|s) \sum_{s'} p(s'|s,a) \;\mathbb{E}[G_{t+1}| S_{t+1}=s']\\
&amp;= \sum_a \pi(a|s) \sum_{s'} \sum_r p(s',r|s,a)\;\mathbb{E}[G_{t+1}| S_{t+1}=s'] \\
&amp;= \sum_a \pi(a|s) \sum_{s',r} p(s',r|s,a)\;\mathbb{E}[G_{t+1}| S_{t+1}=s'] \qquad(6)\\
\end{aligned}\]

<p>Finally, substituting equations 5 and 6 back in 1:</p>

\[\begin{aligned}
v_{\pi}(s) &amp;= \sum_{a}\pi(a|s)\;\sum_{s',r}p(s',r|s,a)\;r \\
&amp;\quad + \gamma \sum_a \pi(a|s) \sum_{s',r} p(s',r|s,a)\;\mathbb{E}[G_{t+1}|S_{t+1}=s']\\
&amp;= \sum_a \pi(a|s) \sum_{s',r} p(s',r|s,a) \big[r + \gamma \mathbb{E}[G_{t+1}|S_{t+1}=s']\big]\\
v_{\pi}(s) &amp;= \sum_a \pi(a|s) \sum_{s',r} p(s',r|s,a) \big[r + \gamma v_\pi(s')\big] \qquad (7)
\end{aligned}\]

<p>Ladies and gentlemen, the Bellman equation.</p>

<p>It was more nuanced that I expected.</p>
:ET